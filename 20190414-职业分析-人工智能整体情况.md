20190414 职业分析-全球AI领域人才报告

### 一、海外精英回流已成大势所驱，美国成为中国领域最大人才回流来源

中国经济的快速发展为中国的互联网及高科技企业的腾飞插上了翅膀。百度，阿里巴巴、腾讯等中国企业在互联网大潮中脱颖而出。在这样的时代背景下，越来越多的海外华人选择回到中国发展。目前，在中国拥有海外工作经验的AI从业者占比9%
![海外经验工作回国.png](https://i.loli.net/2019/04/14/5cb2e6aaaf451.png)

### 二、高校及研究院人才不断流向企业，推动有效的人才合作能双赢
![高校研究工作比例.png](https://i.loli.net/2019/04/14/5cb2e6a9bd95a.png)

科技公司正在不断从各大名牌及研究所招募机器人和机器学习领域的顶尖教师和学生，用绝对的高薪吸引他们加盟

### 三、AI领域人才需求急速增长，基础研究人才成为最大的人才需求点

全球华人AI技术占全球华人技术人才总数的6.8%
![AI领域从业者年限分布.png](https://i.loli.net/2019/04/14/5cb2e6aa273de.png)
![人工领域细分领域人才需求量.png](https://i.loli.net/2019/04/14/5cb2e6aa57b53.png)
![全球AI领域技术人才分布.png](https://i.loli.net/2019/04/14/5cb2e6aa8eaca.png)
![中美人才比例.png](https://i.loli.net/2019/04/14/5cb2e730d9e69.png)
![华人总监.png](https://i.loli.net/2019/04/14/5cb2e730e3336.png)
![教育背景.png](https://i.loli.net/2019/04/14/5cb2e730e5107.png)
![从业者年限.png](https://i.loli.net/2019/04/14/5cb2e7317c2fc.png)
![高校.png](https://i.loli.net/2019/04/14/5cb2e73245af4.png)
![华人占比.png](https://i.loli.net/2019/04/14/5cb2e7324663e.png)
![中美人才top10地区分布.png](https://i.loli.net/2019/04/14/5cb2e73247cb7.png)
![不同极值的人才对比.png](https://i.loli.net/2019/04/14/5cb2e7551859e.png)
![中美细分领域人才分布.png](https://i.loli.net/2019/04/14/5cb2e7556a835.png)
![中美top10雇主.png](https://i.loli.net/2019/04/14/5cb2e755b99d7.png)

Skip to content
 
Search or jump to…

Pull requests
Issues
Marketplace
Explore
 
@BaileyHB 
4
5 1 totalmind/IA-AI
 Code  Issues 0  Pull requests 1  Projects 1  Wiki  Insights  Settings
IA-AI/20190412 职业分析-算法工程师.md
@BaileyHB BaileyHB Rename 20190412 职业分析-自然语言处理.md to 20190412 职业分析-算法工程师.md
01364b4 5 hours ago
396 lines (340 sloc)  22.8 KB
    
人工智能和相关技术对中国就业的影响
经济学家预测，到2030年，人工智能将为全球经济带来15.7万亿美元的财富

人工智能及相关技术在未来20年将取代中国现有的26%的工作岗位，高于对英国的20%的预估，但也能通过提升工作效率和实际收入在中国创造大量新工作机会。根据PWC中央估计值，人工智能对中国就业的净影响可能将创造约12%的竞增岗位，相当于未来20年内增加9,000个就业岗位。

中国大部分新增岗位预计将出现在服务业，预计净增长29%(约9,700万)，尤其是医疗保健等子行业，可能会出现大幅度增长，我们预计建筑业的净增长幅度将达到23%（1,400万），人工智能对工业领域的就业岗位净影响大致偏中性。而预计农业的净流失岗位约为2,200万

替代效应人工智能及其相关科技取代人工的潜力 1.png 2.png 3.png 4.png 5.png 6.png 7.png 8.png 9.png 10.png 11.png 12.png 13.png 14.png

一、岗位
新增岗位
AI撰稿人，撰写AI客户服务chatbots使用的副本;
AI团队的律师，负责管理宝贵的AI知识产权和法律问题;
技术销售总监;将AI创新带入现场，将这些服务与潜在客户联系起来;
AI分析师和战略顾问，为使用和构建AI技术的雇主提供咨询和战略建议;
AI团队的营销经理，为将AI技术作为产品或服务的公司建立知名度和高级客户群;
用户体验或AI的“UX”设计人员，他们是创造性人才，负责为客户构建优雅易用的AI界面;
AI新闻工作者，覆盖快速发展的深度学习和人工智能行业的新闻。
无人驾驶汽车调度员
AI立法专家、学者
AI训练师
机器人任务编排专家
方言采集者
二、职责
主要职责
与我们的数据科学家和软件架构师紧密合作，开发和维护我们的核心产品
评估和分析现有的数据，构造新的数据集，以产生基本的见解，或用于培训 NLP 模型
开发高度可伸缩的代码，利用自然语言处理和基于规则的模型集成到我们的数据管道中
调整、部署、评估和改进 NLP 模型(Python、 Tensorflow、 Jupyter 笔记本)
致力于新特性的实现，保证正确的实现，良好的文档化和按时交付
时刻关注创造和改进的机会。 从我们的开发过程，到最终的用户体验
知识、技能和能力
使用 NLP 的经验
使用 Python 的扎实技能
使用最先进的深度学习方法的扎实经验，例如建立神经网络，包括 DNNs，RNNs，bLSTMs，gru 和 / 或在该领域的出版记录
优秀的分析、概念和解决问题的能力
对敏捷和精益原则的痴迷(GitHub，Trello)
三、学习工具
Dataset release
A paper accepted at EMNLP 2018 presented a benchmark dataset for machine translation of noisy text (MTNT), consisting of Reddit comments and professionally sourced translations. It differs from previous datasets which are mostly synthetically generated
Quora has publicly released a dataset called Question Sincerity, where the goal is to feed the data to a machine learning model and train it to be able to distinguish well-intentioned questions from provocative ones. The idea is to be able to capture those ill-intentioned questions, flag them, and remove them from the platform so as to reduce any harm that such information could cause to the community. The dataset was also released on Kaggle as a competition.
Google releases an image captioning dataset called Conceptual Captions. This dataset was released as part of a research paper presented at ACL 2018
Gab.ai corpus is a large-scale dataset for studying hate speech and toxicity on social media platforms.
A new large-scale dataset and task for visual common sense reasoning has been made publicly available, with the goal to enable cognition-level understanding in AI systems.
Facebook and New York University released a dataset called XNLI which was created for evaluating cross-lingual approaches to natural language understanding (NLU). XNLI also includes baselines that can assist researchers to create systems that understand multiple languages.
ShaRC is a dataset that focuses on building end to end conversational question answering systems that support the addition of background knowledge, especially when the system tries to answer a more difficult question, where the answer is not directly in the text source.
Question Answering in Context (QuAC), is a dataset consisting of data instances representing dialog between two crowd workers. It is useful for modeling, understanding, and participating in information seeking dialog.
Amazon releases sales rank dataset for kindle and print books.
Dataset released by Rada Mihalcea can be used to build fake news detection systems.
Alexa scientist releases FEVER, a public dataset containing 185,000 data instances useful for fact extraction and verification.
IBM releases a dataset which includes information that can be leveraged to build more comprehensive QA systems based on knowledge and reasoning.
In an effort to build more representative ML models and promote inclusiveness in AI, Google AI announces the Inclusive Images Competition on Kaggle. The challenge is to build robust image captioning tools that work even for images that contain underrepresented groups based on the Open Images dataset.
TwentyBN has released a massive video dataset (Something-Something V2) to help enable systems to have the ability of video understanding and visual common sense.
A new version of FastText includes pre-trained word embeddings in 157 languages, a resource which is useful for those working on multilingual research.
Microsoft releases a massive collection of free datasets for advancing NLP and machine learning research.
SWAG is a new natural language inference dataset which was presented at the EMNLP 2018 conference. The dataset consists of adversarial generated and human-verified question-answer pairs, which are useful to test language modeling, question-answering, or natural language inference systems.
DeepMind open sources their dataset used to train generative query networks (GQNs) for neural scene representation and rendering.
A song lyric toxicity dataset is made available accompanied by analysis and slides.
FAIR releases dataset which can be useful to train AI Agents to teach other visual navigation.
Here is a nice dataset which contains short jokes scraped from various websites.
A dataset and model for comprehending paragraphs describing processes.
Google releases a dataset and challenge for landmark recognition.
DataTurks offers several open datasets and offers a neat interface to explore them.
CoDraw is a dataset used for training a task that enables collaborative drawing between two agents using natural language understanding from dialog.
Microsoft released 125 million building footprints from the US as open data
IBM releases a dataset of recorded debates containing 60 speeches (audio + ASR & human transcripts). Useful for conducting different NLP tasks such as argument detection and argument stance classification.
Here is an alphabetical list of NLP related datasets.
Google announces Open Image V4 which contains 15.4 bounding-boxes for 600 categories on 1.9M images. Google claims this is the largest existing dataset with object location annotations.
Amazon is working on making a large-scale fact extraction and verification dataset publicly available. Learn more about their efforts here.
learning resources
Deep Learning and Reinforcement Learning Summer School, Toronto 2018
Elvis Saravia and Soujanya Poria release a project called NLP-Overview that is intended to help students and practitioners get a condensed overview of modern deep learning techniques applied to NLP, including theory, algorithms, applications, and state-of-the-art result.

Lecture material is available for Sebastian Raschka’s new ML course given at the University of Washington Madison.

OpenAI releases a new educational package, called Spinning Up in Deep RL, for those interested in learning about the topic of deep reinforcement learning. It includes an extensive list of algorithms and resources used to effectively train deep reinforcement learning algorithms.

Yandex School of Data Analysis (YSDA) releases material for their new NLP course (GitHub repo).

NYU announces a course called “Neural Aesthetics” for learning how to teach different artistic capabilities to neural networks.

Stanford released a new course called “TensorFlow for Deep Learning Research”. It contains full lecture notes and slides covering topics such as convnets, generative adversarial networks (GANs), transformer, Tensor2Tensor, and much more.

Stanford also released slides for all the NLP related seminars for Fall 2018, which include emerging topics such as multi-task learning, semantic role labeling, and visual questions answering.

Deeplizard releases a new course covering the fundamentals of neural networks and tensor math, taught purely with PyTorch.

Shervine Amidi releases a neat website containing several deep learning and machine learning cheat-sheets. The guides are available in several languages.

Berkley AI Research (BAIR) offers new “Intro to AI” course

Rule of Machine Learning:Best Practices for ML engineering- for deploying realworld ML-based apps provided by Google’s ML team.

Here is a mini-course on Deep Learning with PyTorch (lecture slides and code included).

Bloomberg is offering a new course on “Foundations of Machine Learning”

Facebook is investing efforts to teach machine learning in an intuitive way (in a six-part video series) to learners from all different backgrounds.

The University of Texas is offering a new course on Linear Algebra hosted on edX.
Sebastian Ruder releases NLP Progress, a repository to keep track of state-of-theart results in NLP research.

Google releases new machine learning course for free.

As part of the ML Education project, Google releases ML Learning Guides which are a set of tutorials to teach step-by-step machine learning essentials and best practices

Moustapha Cisse, the founder of Google AI Ghana, introduces new one-year intensive Master’s Program for Machine Intelligence in Africa.

The Gradient is a publication that aims to democratize AI through educational content.

The Gradient is a publication that aims to democratize AI through educational content.

Washington University (in St. Louis) opens course “T81-558: Applications of Deep Neural Networks” (includes Jupyter notebooks).

Yann LeCun, Mikael Henaff, and Alfredo Canziani released a new course on deep learning that aims to teach the latest techniques in deep learning and representation learning.

Stanford released a new course for NLP called “CS224n: NLP with Deep Learning”.

Egor Polusmak releases a machine learning course which consists of topics such as visual data analysis with Python and unsupervised learning.

Deeplearning.ai releases new course on sequence models, introducing topics such as GRUs, LSTMs, and Recurrent Neural Networks (RNNs). This specialization is taught by Andrew Ng.

BOOKS
Deeplearning.ai releases new course on sequence models, introducing topics such as GRUs, LSTMs, and Recurrent Neural Networks (RNNs). This specialization is taught by Andrew Ng.
Will Ratcliff discuss methods to capture the curiosity and imagination of your audience when delivering scientific presentations.
Andrew Trask releases his new book entitled “Grokking Deep Learning” where he aims to teach deep learning and related mathematical concepts in a more intuitive way using Numpy (notebooks included).
Terence Parr and Jeremy Howard released an online book called “The Matrix Calculus You Need for Deep Learning”, which discusses the fundamental math you need for applying deep learning to various problems.
“Fairness and Machine Learning: Limitations and Opportunities” is an online textbook discussing fairness in machine learning.
Andrew Ng releases a book called “Machine Learning Yearning” where he teaches how to structure Machine Learning projects.
Goku Mohandas released a set of notebooks (called Practical AI) that teaches how to program machine learning models using a practical approach via PyTorch.
Bharath Ramsundar and Reza Zadeh published a book on “TensorFlow for Deep Learning” which covers topics that range from linear regression to Reinforcement Learning.
Ian Goodfellow publicly releases LaTeX files for the notations used in his “Deep Learning” book.
Newsletters and Podcasts
This week in AI by Denny Britz
NLP News by Sebastian Ruder
NLP Highlights (podcast) by Matt Gardner and Waleed Ammar
Deep Learning Weekly
nathan.ai newsletter by Nathan Benaich
Alignment Newsletter
AI Diary by Elvis Saravia
The Creative AI Newsletter
NLP Newsletter by Elvis Saravia
Open source
t, the field wouldn’t be where it is now if it were not for the great efforts made by developers as well. It’s important to understand the role software engineering plays in research.

Google AI releases Dopamine, a TensorFlow-based framework that provides flexibility, stability, and reproducibility for new and experienced reinforcement learning researchers.
TensorFlow announces Tensorflow.js, a Web-GL accelerated, browser-based JavaScript library for training and deploying ML models on the web.
TensorFlow releases a beginner’s guide on how to apply probabilistic programming to real-world problems. It basically serves as a guide on how to leverage TensorFlow Probability, a library built for scientists, statisticians, and ML researchers, to encode domain knowledge to understand data and make predictions.
Google releases Cirq, an open source tool which enables researchers to write quantum algorithms for quantum processors such as those used for NISQ computers.
GluonNLP is a tool for reproducing state-of-the-art research in NLP. It provides several implementations and features that makes it easier to build NLP-based prototypes and products.
The Facebook AI team has released pytext, a set of NLP libraries and pre-built models built on top of PyTorch that provide functionalities to build NLP 46 applications that scale and are efficient at inference time. The library is mostly aimed at developers rather than researchers.
Google AI releases What-If Tool, a TensorBoard feature to help users better understand their machine learning models without writing code.
The TensorFlow team releases AutoAugment which consists of a series of modules provided on TFHub that allows researchers to train better image models with fewer data using image augmentation tricks.
Google releases Dataset Search, a platform to quickly and efficiently search and find open datasets which have been uploaded to public sites such as personal websites and university profiles.
Earlier last week, Facebook AI research team released wav2letter — “a simple and efficient end-to-end Automatic Speech Recognition (ASR) system.” The toolkit provides pre-trained models that can get you started right away with transcribing speech. The accompanying paper can also be found here.
The Facebook research team introduces DensePose, a real-time approach for mapping human pixels from 2D images to 3D surface model of a human body.
The Natural Language Decathlon (decaNLP) benchmark offers a unique setting for studying general NLP models that can perform several natural language tasks.
DGL is a library to build graph neural networks including Graph Convolutional Networks.
With TensorBoardX, now you can use TensorBoard with many other deep learning frameworks such as PyTorch, Chainer, MXNet, among others
Google's MLPerf is an effort that aims to build a common set of machine learning benchmarks to measure system performance for both training and inference from mobile devices to cloud services.
Salesforce’s Einstein AI team releases TransmogrifAI, an AutoML library that focuses on accelerating machine learning developer productivity through automated machine learning for structured data.
Papers with Code is a web tool for searching machine learning papers that contain open source code.
The MXNet team releases GluonCV, a deep learning toolkit that lets engineers and researchers quickly develop new algorithms and baselines (for image recognition, object detection, and semantic segmentation)
DeepSuperLearner is an implementation of deep ensemble methods for tackling classification problems.
Pythia is a modular framework that won the visual question answering challenge presented by FAIR
OpenAI announced an efficient method, called gradient-checkpointing, to train memory-efficient and fast deep neural networks
You can find all of Facebook’s open source projects here. It includes PyTorch, Caffe2, ONNX, Tensor Comprehensions and much more.
Google offers free access to GPUs on their online collaborative notebook service called Google Colab.
ml5.js is an open source web development tool, built on top of Tensorflow.js, that lets users easily access machine learning algorithms and models on the browser.
FAIR releases code for the paper "Colorless green recurrent networks dream hierarchically”. This is another work that aims to understand what recurrent architectures are learning and to what extent they are effective at modeling hierarchical structure
FAIR releases PyTorch implementation of “Poincaré Embeddings for Learning Hierarchical Representations”. This paper was published in NeurIPS 2017 and proposed an approach for learning hierarchical representations of symbolic data by embedding then into hyperbolic space.
JupyterLab is released in beta version, and developers say that it is ready for mass user adoption.
The Facebook AI research team releases a more efficient implementation of RCNN and Mask R-CNN using PyTorch 1.0. The modular implementations can be used for instance segmentation and object detection.
Peter Norvig releases Lisp code for the textbook “Paradigms of Artificial Intelligence Programming”.
TensorFlow implementation of the Capsule Network model implemented in the paper “Dynamic Routing between Capsules”.
TextQL is a library that allows you to execute against CSV or TSV text files.
PolygonRNN++ is a new interactive annotation tool for segmentation datasets.
FAIR share open source tools for fastMRI with the aim to increase the efficiency and speed of processing MRI scans (up to 10x times faster).
CoinRun is a training environment developed by OpenAI which provides a metric for an agent’s ability to generalize across new environments, which is a challenging task in deep reinforcement learning.
DeepMind releases GraphNets, which is an easy-to-use library for training graphbased neural networks
Stateoftheart.ai is a platform for crowdsourcing state-of-the-art results in different areas of AI research such as reinforcement learning and natural language processing
Muppet Show is a web interface that allows you to explore how language is seen and analyzed by models such as BERT and ELMo. It consists of a visualization tool where you can query for specific tokens and find similar contexts to them.
Jonathan Kummerfeld has developed an impressive web page to visualize and showcase a neural Part-of-Speech tagger using various deep learning toolkits such as Dynet, PyTorch, and TensorFlow.
Zaid Alyafeai releases code for his image-to-image translation system which operates on the browser. The system implements the pix2pix paper and was developed to work on the browser using Tensorflow.js.
Here is a beautiful website called REGEXPER which allows you to test your regular expressions on the browser.
A new medical imaging framework (Medical Torch), based on PyTorch, has been open sourced by Christian Perone. The idea with this tool is to simplify the steps of pre-processing MRI data.
Code release for MojiTalk, which is a system used to generate emotional responses at scale.
TensorFlow introduces SPINN, a tool that enables natural language understanding in TensorFlow with eager execution.
Sublime Text 3.1 is released.
Test Tube is a library to track and optimize deep learning experiments which allows researchers to easily log experiments and parallelize hyperparameter search.
Facebook AI Research (FAIR) release "Tensor Comprehensions", which is a library that aims to bridge the gap between researchers and engineers who work together in ML research and implementations.
TorchFold is a tool built on top of PyTorch that makes it easy to batch anything regardless of the complexity of your dynamic architectures
NCRF++ is an open-source neural sequence labeling toolkit.
HuggingFace introduces NeuralCoref which is a fast and efficient coreference resolution tool built with neural networks and SpaCy.
TextDistance is a python library for comparing the distance between two or more sequences. Implements various algorithms such as Hamming, Jaccard index, etc.
DL-Text is a repository containing code on how to pre-process textual data for deep learning models built with TensorFlow.
© 2019 GitHub, Inc.
Terms
Privacy
Security
Status
Help
Contact GitHub
Pricing
API
Training
Blog
About
